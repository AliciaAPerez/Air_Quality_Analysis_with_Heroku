{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import time as tm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Excel File\n",
    "def city_data():\n",
    "    # Creating File Path for Excel File\n",
    "    filePath = \"../Data/CA_Pop_Census_2010_2019_by_city.xlsx\"\n",
    "    excel_df = pd.DataFrame(pd.read_excel(filePath))\n",
    "    \n",
    "    # Converting Excel to CSV for Ease\n",
    "    excel_df.to_csv (\"CA_Pop_Census_2010_2019_by_city.csv\",  \n",
    "                    index=None,\n",
    "                    header=None)\n",
    "    \n",
    "    # Creating DataFrame\n",
    "    df = pd.DataFrame(pd.read_csv(\"CA_Pop_Census_2010_2019_by_city.csv\"))\n",
    "    \n",
    "    # Cleaning CSV\n",
    "    # Dropping UnWanted Columns and Indices\n",
    "    df = df.drop(columns=[\"Unnamed: 1\", \"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\", \"Unnamed: 5\", \"Unnamed: 6\", \"Unnamed: 7\",\n",
    "                         \"Unnamed: 8\", \"Unnamed: 9\", \"Unnamed: 10\", \"Unnamed: 11\", \"Unnamed: 12\"],\n",
    "                index=[0,1,484,485,486,487,488])\n",
    "    # Renaming Column 0\n",
    "    df = df.rename(columns={\"Annual Estimates of the Resident Population for Incorporated Places in California: April 1, 2010 to July 1, 2019\": \"City\"})\n",
    "    # Parsing City Column\n",
    "    df[\"City\"] = df[\"City\"].str.split(\",\", n=1, expand=True)\n",
    "    # Dropping City and Town\n",
    "    df[\"City\"] = df[\"City\"].str.split(\"city\", n=1, expand=True)\n",
    "    df[\"City\"] = df[\"City\"].str.split(\"town\", n=1, expand=True)\n",
    "    \n",
    "    # Converting df to List\n",
    "    return df['City'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    # Setting Up Splinter\n",
    "    executable_path = {'executable_path': \"C:/Windows/chromedriver\"}\n",
    "    return Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_info():\n",
    "#     # Calling init_browser Function\n",
    "#     browser = init_browser()\n",
    "    \n",
    "#     # Calling city_list Function\n",
    "#     city_list = city_data()\n",
    "    \n",
    "#     # Creating List of Current AQI Data\n",
    "#     currentAQI = []\n",
    "    \n",
    "#     baseUrl = 'https://www.airnow.gov/?'\n",
    "#     state = 'CA'\n",
    "#     country = 'USA'\n",
    "    \n",
    "#     for city in city_list:\n",
    "#         # Building URL Query\n",
    "#         url_air_now = baseUrl + 'city=' + city + '&state=' + state + '&country=' + country\n",
    "\n",
    "#         # Visiting URL \n",
    "#         browser.visit(url_air_now)\n",
    "#         # Visiting the URL Takes Some Time, Using the Time Module to Slow Down the Run\n",
    "#         tm.sleep(1)\n",
    "\n",
    "#         # Scrape page into Soup\n",
    "#         html = browser.html\n",
    "#         soup = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "        \n",
    "#         try:\n",
    "#             # Scraping Date & Time\n",
    "#             aqUpdateTime = soup.find('span', class_='aq-updated-time')\n",
    "#             currentDateTime = aqUpdateTime.text\n",
    "#             currentTime = currentDateTime.rsplit('PST')[0] + 'PST'\n",
    "#             currentDate = currentDateTime.rsplit('PST')[1]\n",
    "\n",
    "#             # Scraping Current Pollutant\n",
    "#             aqiItem = soup.find('div', class_='aqi')\n",
    "#             aqi = aqiItem.find('b').text\n",
    "#             pollutantItem = soup.find('div', class_='pollutant')\n",
    "#             pollutant = pollutantItem.find('b').text\n",
    "\n",
    "#             # Appending Dictionary to List\n",
    "#             currentAQI.append({\"City\": city, \"Time\": currentTime, \"Date\": currentDate,\n",
    "#                               \"Current AQI Value\": aqi, \"Current Pollutant\": pollutant})\n",
    "#         except IndexError:\n",
    "#             next\n",
    "            \n",
    "#     # Closing Browser\n",
    "#     browser.quit()\n",
    "  \n",
    "#     # Creating CSV of currentAQI\n",
    "#     currentAQI = pd.DataFrame(currentAQI)\n",
    "#     currentAQI.to_csv('../Data/currentAQIData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sleeper():\n",
    "#     scrape_info()\n",
    "# while True:\n",
    "#   sleeper()\n",
    "#   tm.sleep(3600)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyPythonEnv",
   "language": "python",
   "name": "mypythonenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
